<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Google Scholar Meta Tags -->
    <meta name="citation_title" content="Inspecting Deep NLP Models: Innovative Techniques for Explainability, Fairness, and Concept Drift in Natural Language Classification">
    <meta name="citation_author" content="Greco, Salvatore">
    <meta name="citation_publication_date" content="2024/10/28">
    <meta name="citation_dissertation_institution" content="Politecnico di Torino">
    <meta name="citation_pdf_url" content="https://grecosalvatore.github.io/thesis/Greco_PhD_Thesis_2024.pdf">
    <meta name="citation_language" content="en">

    <!-- Dublin Core Meta Tags -->
    <meta name="DC.title" content="Inspecting Deep NLP Models: Innovative Techniques for Explainability, Fairness, and Concept Drift in Natural Language Classification">
    <meta name="DC.creator" content="Greco, Salvatore">
    <meta name="DC.date" content="2024-10-28">
    <meta name="DC.type" content="Dissertation">
    <meta name="DC.format" content="application/pdf">
    <meta name="DC.language" content="en">
    <meta name="DC.publisher" content="Politecnico di Torino">

    <!-- General Meta Tags -->
    <meta name="description" content="PhD Thesis by Salvatore Greco on Explainability, Fairness, and Concept Drift in Deep NLP Models. Politecnico di Torino, 2024.">
    <meta name="author" content="Salvatore Greco">
    <meta name="keywords" content="NLP, Deep Learning, Explainability, XAI, Fairness, Concept Drift, Natural Language Processing, Machine Learning, Trustworthy AI">

    <!-- Open Graph Meta Tags -->
    <meta property="og:title" content="PhD Thesis: Inspecting Deep NLP Models">
    <meta property="og:description" content="Innovative Techniques for Explainability, Fairness, and Concept Drift in Natural Language Classification">
    <meta property="og:type" content="article">
    <meta property="og:url" content="https://grecosalvatore.github.io/thesis/">

    <title>PhD Thesis - Salvatore Greco - Politecnico di Torino</title>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, 'Helvetica Neue', Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            background-color: #f5f5f5;
            padding: 20px;
        }

        .container {
            max-width: 900px;
            margin: 0 auto;
            background-color: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        h1 {
            color: #2c3e50;
            font-size: 2em;
            margin-bottom: 20px;
            line-height: 1.3;
        }

        .meta-info {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 6px;
            margin: 20px 0;
        }

        .meta-info p {
            margin: 8px 0;
        }

        .meta-info strong {
            color: #2c3e50;
            display: inline-block;
            min-width: 140px;
        }

        h2 {
            color: #34495e;
            font-size: 1.5em;
            margin-top: 30px;
            margin-bottom: 15px;
        }

        .abstract {
            text-align: justify;
            margin: 20px 0;
        }

        .abstract p {
            margin-bottom: 15px;
        }

        .buttons {
            display: flex;
            gap: 15px;
            margin-top: 30px;
            flex-wrap: wrap;
        }

        .button {
            display: inline-flex;
            align-items: center;
            gap: 8px;
            padding: 12px 24px;
            text-decoration: none;
            border-radius: 6px;
            font-weight: 500;
            transition: all 0.3s ease;
        }

        .button-primary {
            background-color: #3498db;
            color: white;
        }

        .button-primary:hover {
            background-color: #2980b9;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(52, 152, 219, 0.3);
        }

        .button-secondary {
            background-color: #95a5a6;
            color: white;
        }

        .button-secondary:hover {
            background-color: #7f8c8d;
            transform: translateY(-2px);
            box-shadow: 0 4px 12px rgba(149, 165, 166, 0.3);
        }

        .back-link {
            display: inline-block;
            margin-top: 30px;
            color: #3498db;
            text-decoration: none;
        }

        .back-link:hover {
            text-decoration: underline;
        }

        @media (max-width: 768px) {
            .container {
                padding: 20px;
            }

            h1 {
                font-size: 1.5em;
            }

            .buttons {
                flex-direction: column;
            }

            .button {
                width: 100%;
                justify-content: center;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Inspecting Deep NLP Models: Innovative Techniques for Explainability, Fairness, and Concept Drift in Natural Language Classification</h1>

        <div class="meta-info">
            <p><strong>Author:</strong> Salvatore Greco</p>
            <p><strong>Institution:</strong> Politecnico di Torino</p>
            <p><strong>Defense Date:</strong> October 28, 2024</p>
            <p><strong>Type:</strong> PhD Dissertation</p>
        </div>

        <h2>Abstract</h2>
        <div class="abstract">
            <p>
                In the last decade, NLP has experienced remarkable advancements, achieving performance levels previously unimaginable, with models even surpassing human performance in certain tasks. However, despite their accuracy and capabilities, deep learning-based NLP models still face several challenges that limit their trustworthiness and responsible use in real-world applications.
            </p>
            <p>
                This research addresses these challenges by designing innovative techniques for inspecting deep learning NLP classifiers to increase their transparency, fairness, and robustness. We focus on three major challenges: (1) Explaining predictions to make model decisions interpretable and trustworthy; (2) Identifying and mitigating bias to ensure fair treatment across different demographic groups; (3) Detecting performance degradation over time due to concept and data drift to maintain model reliability in dynamic environments.
            </p>
            <p>
                The thesis presents novel methodologies combining machine learning, natural language processing, and explainable AI techniques. These contributions advance the state-of-the-art in trustworthy AI, providing practitioners and researchers with tools to build more transparent, fair, and robust NLP systems.
            </p>
        </div>

        <div class="buttons">
            <a href="https://grecosalvatore.github.io/thesis/Greco_PhD_Thesis_2024.pdf" class="button button-primary" target="_blank" rel="noopener noreferrer">
                üìÑ Download PDF
            </a>
            <a href="https://hdl.handle.net/20.500.14242/170882" class="button button-secondary" target="_blank" rel="noopener noreferrer">
                üîó View on Repository
            </a>
            <a href="https://iris.polito.it/handle/11583/2993905" class="button button-secondary" target="_blank" rel="noopener noreferrer">
                üîó IRIS Polito
            </a>
        </div>

        <a href="https://grecosalvatore.github.io/" class="back-link">‚Üê Back to main website</a>
    </div>
</body>
</html>